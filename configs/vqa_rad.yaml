# VQA-RAD Experiment Configuration
# Based on Med-PaLM M paper (Table A.1, A.2)

dataset:
  name: vqa_rad
  train_split: train
  test_split: test
  image_size: 224
  num_workers: 4

model:
  name: llava_med  # or blip2
  pretrained: "microsoft/llava-med-v1.5-mistral-7b"
  max_input_tokens: 710   # from paper Table A.2
  max_output_tokens: 256  # from paper Table A.2

training:
  batch_size: 8
  learning_rate: 5.0e-5   # from paper Table A.2
  num_epochs: 20
  warmup_steps: 100
  dropout: 0.1
  optimizer: adafactor     # paper uses Adafactor
  momentum_beta1: 0.9     # from paper Section 4.2
  use_one_shot_exemplar: true

evaluation:
  metrics:
    - bleu_1
    - f1_token
  # Paper baselines for comparison (Table 2)
  paper_baselines:
    palm_e_84b:
      bleu_1: 59.19
      f1: 38.67
    med_palm_m_12b:
      bleu_1: 64.02
      f1: 50.66
    med_palm_m_84b:
      bleu_1: 69.38
      f1: 59.90
    med_palm_m_562b:
      bleu_1: 71.27
      f1: 62.06
    prior_sota:
      bleu_1: 71.03

prompt:
  instruction: >
    You are a helpful medical assistant. The following are questions
    about medical knowledge. Solve them in a step-by-step fashion,
    referring to authoritative sources as needed.
